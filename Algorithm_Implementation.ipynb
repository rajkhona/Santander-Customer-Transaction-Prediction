{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook comprises of Algorithm implementation and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data.\n",
    "training_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "training_data_copy = training_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_copy.drop('ID_code',inplace = True, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_without_target = training_data_copy.drop(\"target\", axis=1)\n",
    "training_set_with_only_target = training_data_copy[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 200) (140000,)\n",
      "(60000, 200) (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_set_without_target, training_set_with_only_target, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEature Scaling.\n",
    "sc = StandardScaler()\n",
    "## transforming \"training\"\n",
    "X_train = sc.fit_transform(X_train)\n",
    "## transforming \"test\"\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 91.51%\n",
      "****************************************************************************************************\n",
      "Logistic Regression Testing Accuracy: 91.27%\n"
     ]
    }
   ],
   "source": [
    "# Applying logistic regression without any regularization and on imbalanced dataset.\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "train_result = logreg.score(X_train, y_train)\n",
    "test_result = logreg.score(X_test, y_test)\n",
    "print(\"Logistic Regression Training Accuracy: %.2f%%\" % (train_result*100.0))\n",
    "print('*' * 100)\n",
    "print(\"Logistic Regression Testing Accuracy: %.2f%%\" % (test_result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual 0</th>\n",
       "      <th>Actual 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Predicted 0</td>\n",
       "      <td>53101</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Predicted 1</td>\n",
       "      <td>4456</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Actual 0  Actual 1\n",
       "Predicted 0     53101       785\n",
       "Predicted 1      4456      1658"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing Confusion matrix.\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "col=[\"Predicted Dead\",\"Predicted Survived\"]\n",
    "cm=pd.DataFrame(cm)\n",
    "cm.columns=[\"Actual 0\",\"Actual 1\"]\n",
    "cm.index=[\"Predicted 0\",\"Predicted 1\"]\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: Model Analysis\n",
    "If we see our model had accuracy of >90% both on training and testing set however, if we look into confusion matrix we can see that our model has high number of false negative because our dataset is imbalanced. Hence this model makes no sense as it won't be able to predict minority class samples correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.6786737617683176\n",
      "Recall score: 0.27118089630356557\n",
      "F1 Score: 0.3875189903003389\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics.\n",
    "\n",
    "# A) Print Precision (TP/ (TP+FP))\n",
    "print(\"Precision score: {}\".format(precision_score(y_test,y_pred)))\n",
    "\n",
    "# B) Recall – What percent of your predictions were correct? Recall = TP/(TP+FN)\n",
    "\n",
    "print(\"Recall score: {}\".format(recall_score(y_test,y_pred)))\n",
    "\n",
    "# C) F1 score – What percent of positive predictions were correct? F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Area Under Curve.\n",
    "lr_auc = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6283065525202643"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New strategy to balance out data - Synthetic Minority Oversampling Technique(SMOTE)\n",
    "A problem with imbalanced classification is that there are too few examples of the minority class for a model to effectively learn the decision boundary.\n",
    "\n",
    "One way to solve this problem is to oversample the examples in the minority class. This can be achieved by simply duplicating examples from the minority class in the training dataset prior to fitting a model. This can balance the class distribution but does not provide any additional information to the model.\n",
    "\n",
    "An improvement on duplicating examples from the minority class is to synthesize new examples from the minority class. This is a type of data augmentation for tabular data and can be very effective.\n",
    "\n",
    "Perhaps the most widely used approach to synthesizing new examples is called the Synthetic Minority Oversampling TEchnique, or SMOTE for short. This technique was described by Nitesh Chawla, et al. in their 2002 paper named for the technique titled “SMOTE: Synthetic Minority Over-sampling Technique.”\n",
    "\n",
    "SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line.\n",
    "\n",
    "Specifically, a random example from the minority class is first chosen. Then k of the nearest neighbors for that example are found (typically k=5). A randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 102800, 1: 71960})\n"
     ]
    }
   ],
   "source": [
    "# Applying SMOTE.\n",
    "from collections import Counter\n",
    "from numpy import where\n",
    "from matplotlib import pyplot\n",
    "over = SMOTE(sampling_strategy=0.4)\n",
    "under = RandomUnderSampler(sampling_strategy=0.7)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X1, y1 = pipeline.fit_resample(training_set_without_target,training_set_with_only_target)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y1)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New target variable distribution.\n",
    "Old distribution aprrox 1:10\n",
    "New distribution aprrox 7:10\n",
    "\n",
    "We can clearly see we have generated enough sample points for minortiy class and now let's see how our algorithm is performing on this new distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122331, 200) (122331,)\n",
      "(52428, 200) (52428,)\n"
     ]
    }
   ],
   "source": [
    "# Performing Train Test Split.\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X1, y1, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train1.shape, y_train1.shape)\n",
    "print(X_test1.shape, y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Feature Scaling.\n",
    "sc = StandardScaler()\n",
    "\n",
    "## transforming \"training\"\n",
    "X_train1 = sc.fit_transform(X_train1)\n",
    "## transforming \"test\"\n",
    "X_test1 = sc.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 79.92%\n",
      "****************************************************************************************************\n",
      "Logistic Regression Testing Accuracy: 79.87%\n"
     ]
    }
   ],
   "source": [
    "# Applying Logistic Regression on balanced dataset along with it we are using lasso Regularization \n",
    "# so as to minimize the effect of unnecessary predictors.\n",
    "\n",
    "logreg1 = LogisticRegression(penalty='l1', solver='saga')\n",
    "\n",
    "logreg1.fit(X_train1,y_train1)\n",
    "\n",
    "y_pred1 = logreg1.predict(X_test1)\n",
    "\n",
    "train_result1 = logreg1.score(X_train1, y_train1)\n",
    "test_result1 = logreg1.score(X_test1, y_test1)\n",
    "print(\"Logistic Regression Training Accuracy: %.2f%%\" % (train_result1*100.0))\n",
    "print('*' * 100)\n",
    "print(\"Logistic Regression Testing Accuracy: %.2f%%\" % (test_result1*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual 0</th>\n",
       "      <th>Actual 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Predicted 0</td>\n",
       "      <td>26009</td>\n",
       "      <td>4659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Predicted 1</td>\n",
       "      <td>5895</td>\n",
       "      <td>15865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Actual 0  Actual 1\n",
       "Predicted 0     26009      4659\n",
       "Predicted 1      5895     15865"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test1,y_pred1)\n",
    "col=[\"Predicted Dead\",\"Predicted Survived\"]\n",
    "cm=pd.DataFrame(cm)\n",
    "cm.columns=[\"Actual 0\",\"Actual 1\"]\n",
    "cm.index=[\"Predicted 0\",\"Predicted 1\"]\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: Model Analysis\n",
    "If we see our new model it has reduced the number of false negatives and is better at predicting minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Area Under Curve\n",
    "lr_auc = roc_auc_score(y_test1, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885863827931394"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we compare AUC with original model there is a significant improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.7729974663808225\n",
      "Recall score: 0.7290900735294118\n",
      "F1 Score: 0.7504020433260808\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Metrics\n",
    "print(\"Precision score: {}\".format(precision_score(y_test1,y_pred1)))\n",
    "\n",
    "# B) Recall – What percent of your predictions were correct? Recall = TP/(TP+FN)\n",
    "\n",
    "print(\"Recall score: {}\".format(recall_score(y_test1,y_pred1)))\n",
    "\n",
    "# C) F1 score – What percent of positive predictions were correct? F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test1,y_pred1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There has been a significant improvement in Recall and F1 score as compared to original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's plot ROC Curve for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# predict probabilities\n",
    "y_pred_proba = logreg.predict_proba(X_test) # because roc curve needs actual labels and predicted probabilities\n",
    "clf_pred_proba = logreg1.predict_proba(X_test1) # because roc curve needs actual labels and predicted probabilities\n",
    "\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "y_pred_proba = y_pred_proba[:, 1]\n",
    "clf_pred_proba = clf_pred_proba[:, 1]\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "lr_fpr1, lr_tpr1, _ = roc_curve(y_test1, clf_pred_proba)\n",
    "\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "pyplot.plot(lr_fpr1, lr_tpr1, marker='.', label='After applying SMOTE')\n",
    "\n",
    "\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate (1 - Specificity)')\n",
    "pyplot.ylabel('True Positive Rate (Specificity)')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion-\n",
    "We can conclude that algorithms like Logistic Regression are inefficient at handling imbalanced data and SMOTE technique proves to be very efficient when trying to balance out data it alos help's model to predict minority class efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Predictions on Validation set.\n",
    "\n",
    "validation_set = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set.drop('ID_code', axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>8.8100</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>5.9739</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>8.3442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>7.4578</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>7.1437</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0    var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950  20.2537   \n",
       "3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397  20.5660   \n",
       "4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595  10.6048   \n",
       "\n",
       "    var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  2.1337  8.8100  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1 -4.4131  5.9739  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  1.5233  8.3442  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  3.3755  7.4578  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  2.9890  7.1437  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling.\n",
    "validation_set_scaling = sc.transform(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = logreg1.predict(validation_set_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "submission =  test_data.copy()\n",
    "submission['Final Predictions'] = final_pred\n",
    "# FinalLogisticPredictions.Survived = FinalLogisticPredictions.Survived.astype(int)\n",
    "\n",
    "submission.to_csv(\"ValidationPredictions.csv\")\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_check = pd.read_csv('ValidationPredictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>Final Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code  Final Predictions\n",
       "0  test_0                  1\n",
       "1  test_1                  1\n",
       "2  test_2                  0\n",
       "3  test_3                  1\n",
       "4  test_4                  0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_check[['ID_code', 'Final Predictions']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "from joblib import dump, load\n",
    "filename1 = 'logistic_model.sav'\n",
    "filename2 = 'SMOTE_Logistic_Model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logistic_model.sav']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(logreg, 'Logistic_model.sav') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SMOTE_Logistic_model.sav']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(logreg1, 'SMOTE_Logistic_model.sav') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
